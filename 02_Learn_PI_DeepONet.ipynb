{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7b95cd-17d4-4dc8-b45e-ffca2c164d6f",
   "metadata": {},
   "source": [
    "# Learning of a Physics-informed DeepONet for quantum graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25db134-6e19-48ee-804d-a4697fc9d160",
   "metadata": {},
   "source": [
    "In this notebook, we want to learn a *DeepONet* for the advection-diffusion equation considered in our paper.\n",
    "The codes use the github repository accompanying the paper Physics-informed DeepONets as templates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab2599-53b1-40b5-bd3f-509ebdf9603d",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7860d55-e6e9-4c7f-af6b-ace45a242242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import re\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, vmap, jit, config\n",
    "import jax\n",
    "from tqdm import trange\n",
    "\n",
    "from functools import partial\n",
    "from jax.example_libraries import optimizers\n",
    "from jax.flatten_util import ravel_pytree\n",
    "import itertools\n",
    "from jax import device_put\n",
    "from jax.example_libraries import optimizers\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import sys\n",
    "\n",
    "# Import one example to get PDE (it's the same for all examples)\n",
    "from src.graph import Example0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5dd4e8-ab23-4408-9796-e008e795507b",
   "metadata": {},
   "source": [
    "## Set important parameters and model to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e4289-edf6-4bfc-aad9-b40977e97668",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 0.1\n",
    "\n",
    "# Specify path of data\n",
    "DATA_PATH = f'./PI_DeepONet_Data/variable_velocity_eps{EPS}_n10_nx200_nt1000/'\n",
    "\n",
    "# Specify the model which should be trained\n",
    "# N_WIDTH ... width of the hidden layers\n",
    "# N_SPLIT ... how often the data is split into batches (should be adapted to available hardware)\n",
    "# mode ... number of training samples that are used (0 - 5K samples, 1 - 10K samples, 2 - 20K samples, -1 for testing)\n",
    "\n",
    "N_WIDTH, N_SPLIT, mode = 100, 1, -1\n",
    "#N_WIDTH, N_SPLIT, mode = 100, 2, 1\n",
    "#N_WIDTH, N_SPLIT, mode = 100, 4, 2\n",
    "#N_WIDTH, N_SPLIT, mode = 200, 2, 0\n",
    "#N_WIDTH, N_SPLIT, mode = 200, 4, 1\n",
    "#N_WIDTH, N_SPLIT, mode = 200, 8, 2\n",
    "#N_WIDTH, N_SPLIT, mode = 100, 8, 0\n",
    "\n",
    "# Number of training epochs\n",
    "N_EPOCHS = 20000\n",
    "\n",
    "# Numebr of residual terms per sample used to evaluate pinn loss\n",
    "N_RES_PER_SAMPLE = 101\n",
    "\n",
    "# The model which should be trained, in order to run the code you have to do this for all kinds of edges\n",
    "train_model = 'inner'\n",
    "# train_model = 'inflow'\n",
    "# train_model = 'outflow'\n",
    "\n",
    "# Path were the final parameters should be stored\n",
    "PARAM_PATH = f'./final_params/params_eps_{EPS}_{train_model}_mode_{mode}_width_{N_WIDTH}_split_{N_SPLIT}_epochs_{N_EPOCHS}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6bb6b1-74aa-4564-8298-4ea89ed4cabe",
   "metadata": {},
   "source": [
    "### Identify training and validation data according to `mode` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a35c7-d3f2-4ba3-a57a-fe442ae142d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = '/LOCAL/blja/PI_DeepONet_Data/eps0.1_n100_nx200_nt1000/'\n",
    "# Train indices from examples 2, 4, 6, resp.\n",
    "\n",
    "if mode == -1:\n",
    "    \n",
    "    train_idx_2 = np.arange(1, dtype=np.int16)\n",
    "    train_idx_4 = np.arange(1, dtype=np.int16)\n",
    "    train_idx_6 = np.arange(1, dtype=np.int16)\n",
    "    \n",
    "    val_idx_2 = np.arange(1, 2, dtype=np.int16)\n",
    "    val_idx_4 = np.arange(1, 2, dtype=np.int16)\n",
    "    val_idx_6 = np.arange(1, 2, dtype=np.int16)\n",
    "\n",
    "elif mode == 0:\n",
    "    \n",
    "    train_idx_2 = np.arange(5, dtype=np.int16)\n",
    "    train_idx_4 = np.arange(5, dtype=np.int16)\n",
    "    train_idx_6 = np.arange(5, dtype=np.int16)\n",
    "    \n",
    "    val_idx_2 = np.arange(5, 6, dtype=np.int16)\n",
    "    val_idx_4 = np.arange(5, 6, dtype=np.int16)\n",
    "    val_idx_6 = np.arange(5, 6, dtype=np.int16)\n",
    "    \n",
    "elif mode == 1:\n",
    "    \n",
    "    train_idx_2 = np.arange(10, dtype=np.int16)\n",
    "    train_idx_4 = np.arange(10, dtype=np.int16)\n",
    "    train_idx_6 = np.arange(10, dtype=np.int16)\n",
    "    \n",
    "    val_idx_2 = np.arange(10, 12, dtype=np.int16)\n",
    "    val_idx_4 = np.arange(10, 12, dtype=np.int16)\n",
    "    val_idx_6 = np.arange(10, 12, dtype=np.int16)\n",
    "    \n",
    "elif mode == 2:\n",
    "    \n",
    "    train_idx_2 = np.arange(20, dtype=np.int16)\n",
    "    train_idx_4 = np.arange(20, dtype=np.int16)\n",
    "    train_idx_6 = np.arange(20, dtype=np.int16)\n",
    "    \n",
    "    val_idx_2 = np.arange(20, 24, dtype=np.int16)\n",
    "    val_idx_4 = np.arange(20, 24, dtype=np.int16)\n",
    "    val_idx_6 = np.arange(20, 24, dtype=np.int16) \n",
    "    \n",
    "elif mode == 4:\n",
    "    \n",
    "    train_idx_2 = np.arange(40, dtype=np.int16)\n",
    "    train_idx_4 = np.arange(40, dtype=np.int16)\n",
    "    train_idx_6 = np.arange(40, dtype=np.int16)\n",
    "    \n",
    "    val_idx_2 = np.arange(95, 100, dtype=np.int16)\n",
    "    val_idx_4 = np.arange(95, 100, dtype=np.int16)\n",
    "    val_idx_6 = np.arange(95, 100, dtype=np.int16) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291bcf2-3c19-4a45-ad38-569af38cf51f",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd582545-c6f4-494a-9ba2-6c7e7fee5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataHandling import loadData\n",
    "DATA = loadData(DATA_PATH, train_idx_2, train_idx_4, train_idx_6)\n",
    "FULL_VAL_DATA = loadData(DATA_PATH, val_idx_2, val_idx_4, val_idx_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c381d18-bde9-4a66-9e65-f16edfa73359",
   "metadata": {},
   "source": [
    "Print shapes of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33653158-0f38-4438-ade8-76b209758d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, di in enumerate(DATA):\n",
    "    if i == 3 or i == 6:\n",
    "        print('\\n')\n",
    "    for j, dij in enumerate(di):\n",
    "        print(f'Shape of DATA[{i}][{j}]: {dij.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7b22a-3e2d-4530-be38-27d04c2cfb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.networks_velocity import MLP, FF_MLP, modified_MLP, PI_DeepONet\n",
    "from src.networks_velocity import n_res_data, n_init_data, n_bc_data\n",
    "\n",
    "import optax\n",
    "\n",
    "config.update(\"jax_enable_x64\", False)\n",
    "#jax.config.update('jax_default_device', gpu_device)\n",
    "\n",
    "# Initialize model\n",
    "m = 304 # Number of sensor postions (101 inflow, 101 outflow, 101 initial condition) + 1 velocity component\n",
    "\n",
    "N_DATA_BC = 101\n",
    "\n",
    "branch_layers = [m, N_WIDTH, N_WIDTH, N_WIDTH, N_WIDTH, N_WIDTH, N_WIDTH, N_WIDTH]\n",
    "trunk_layers =  [2, N_WIDTH, N_WIDTH, N_WIDTH, N_WIDTH, N_WIDTH, N_WIDTH, N_WIDTH]\n",
    "\n",
    "# graph is only used to get drift-diffusion PDE (the same for all examples)\n",
    "graph = Example0(eps=EPS)\n",
    "\n",
    "# Set default weights\n",
    "loss_weights = dict({'res': 0.,\n",
    "     'bcs': 0.,\n",
    "     'ics': 1.,\n",
    "     'physics': 1.,\n",
    "     'physics_bcs_single_edge': 0.,\n",
    "     'physics_bcs_inflow': 0.,\n",
    "     'physics_bcs_inner': 0., \n",
    "     'physics_bcs_outflow': 0.,\n",
    "    })\n",
    "\n",
    "scheduler = optax.schedules.exponential_decay(\n",
    "    init_value=1e-3,\n",
    "    transition_steps=2000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "solver = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),  # Clip by the gradient by the global norm.\n",
    "    optax.scale_by_adam(),  # Use the updates from adam.\n",
    "    optax.scale_by_schedule(scheduler),  # Use the learning rate from the scheduler.\n",
    "    # Scale updates by -1 since optax.apply_updates is additive and we want to descend on the loss.\n",
    "    optax.scale(-1.0)\n",
    ")\n",
    "solver_is_lbfgs = False\n",
    "\n",
    "model = PI_DeepONet(graph,\n",
    "                    branch_layers,\n",
    "                    trunk_layers,\n",
    "                    branch_net=FF_MLP,\n",
    "                    trunk_net=FF_MLP,\n",
    "                    solver=solver,\n",
    "                    solver_is_lbfgs=solver_is_lbfgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9e68f-394f-44f0-a504-2c48bbc65441",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model == 'inflow':\n",
    "        \n",
    "    if 'params_inflow' in locals():\n",
    "        model.params = params_inflow\n",
    "        model.opt_state = model.solver.init(params_inflow)\n",
    "\n",
    "    loss_weights['physics_bcs_inflow']=10\n",
    "    loss_weights['physics_bcs_inflow']=1\n",
    "    \n",
    "    RES_DATA, INIT_DATA, BC_DATA = DATA[0:3]\n",
    "    VAL_DATA = FULL_VAL_DATA[0:3]\n",
    "\n",
    "elif train_model == 'inner':\n",
    "    \n",
    "    if 'params_inner' in locals():\n",
    "        model.params = params_inner\n",
    "        model.opt_state = model.solver.init(params_inner)\n",
    "    loss_weights['physics_bcs_inner']=10\n",
    "    loss_weights['physics_bcs_inner']=1\n",
    "    \n",
    "    RES_DATA, INIT_DATA, BC_DATA = DATA[3:6] \n",
    "    VAL_DATA = FULL_VAL_DATA[3:6]\n",
    "\n",
    "    \n",
    "elif train_model == 'outflow':\n",
    "    \n",
    "    if 'params_outlow' in locals():\n",
    "        model.params = params_outflow\n",
    "        model.opt_state = model.solver.init(params_outflow)\n",
    "    loss_weights['physics_bcs_outflow']=10\n",
    "    loss_weights['physics_bcs_outflow']=1\n",
    "    \n",
    "    RES_DATA, INIT_DATA, BC_DATA = DATA[6:] \n",
    "    VAL_DATA = FULL_VAL_DATA[6:]\n",
    "\n",
    "if N_RES_PER_SAMPLE < RES_DATA[1].shape[1]:\n",
    "    key = random.PRNGKey(22)\n",
    "    shuffle_idx = random.permutation(key, RES_DATA[1].shape[1])[:N_RES_PER_SAMPLE]\n",
    "    RES_DATA[1] = RES_DATA[1][:, shuffle_idx, :]\n",
    "    RES_DATA[2] = RES_DATA[2][:, shuffle_idx, :]\n",
    "    \n",
    "    VAL_DATA[0][1] = VAL_DATA[0][1][:, shuffle_idx, :]\n",
    "    VAL_DATA[0][2] = VAL_DATA[0][2][:, shuffle_idx, :]\n",
    "\n",
    "print(f'\\nData for {train_model} model:')\n",
    "print(f'Nummer of res data points: {n_res_data(RES_DATA)}')\n",
    "print(f'Nummer of init data points: {n_init_data(INIT_DATA)}')\n",
    "print(f'Nummer of bc data points: {n_bc_data(BC_DATA)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be82dbb-e870-4dfd-97f5-be8b0a75d808",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4816aa-805b-4a3c-989f-0d570405c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_key = random.PRNGKey(3)\n",
    "model.train(training_key, nEpochs=N_EPOCHS,\n",
    "            weights=loss_weights,\n",
    "            RES_DATA=RES_DATA,\n",
    "            INIT_DATA=INIT_DATA,\n",
    "            BC_DATA=BC_DATA,\n",
    "            N_SPLIT=N_SPLIT,\n",
    "            N_DATA_BC=N_DATA_BC,\n",
    "            VAL_DATA=VAL_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb65d71-8576-4fa1-aef0-1261783637a9",
   "metadata": {},
   "source": [
    "## Generate loss plot and store loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df31a33-b295-45e4-a03d-4790fb6e5ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.figure(figsize=(9,5), clear=True)\n",
    "step = 1\n",
    "L = np.arange(len(model.val_loss_res_log))[::step]\n",
    "\n",
    "plt.semilogy(L, model.val_loss_res_log[::step],\n",
    "             label='res_log', alpha=0.7)\n",
    "plt.semilogy(L, model.val_loss_physics_log[::step],\n",
    "             label='pde_ph_log', alpha=0.7)\n",
    "plt.semilogy(L, model.val_loss_ics_log[::step],\n",
    "             label='ics_log', alpha=0.7)\n",
    "plt.semilogy(L, model.val_loss_bcs_log[::step],\n",
    "             label='bcs_log', alpha=0.7)\n",
    "plt.semilogy(L, model.val_loss_bnd_physics_log[::step],\n",
    "             label='bnd_ph_log', alpha=0.7)\n",
    "plt.gca().set_prop_cycle(None)\n",
    "\n",
    "L = np.arange(len(model.train_loss_res_log))[::step]\n",
    "plt.semilogy(L, model.train_loss_res_log[::step],\n",
    "             linestyle='dashed',\n",
    "             label='res_log', alpha=0.7)\n",
    "plt.semilogy(L, model.train_loss_physics_log[::step],\n",
    "             linestyle='dashed',\n",
    "             label='pde_ph_log', alpha=0.7)\n",
    "plt.semilogy(L, model.train_loss_ics_log[::step],\n",
    "             linestyle='dashed',\n",
    "             label='ics_log', alpha=0.7)\n",
    "plt.semilogy(L, model.train_loss_bcs_log[::step],\n",
    "             linestyle='dashed',\n",
    "             label='bcs_log', alpha=0.7)\n",
    "plt.semilogy(L, model.train_loss_bnd_physics_log[::step],\n",
    "             linestyle='dashed',\n",
    "             label='bnd_ph_log', alpha=0.7)\n",
    "\n",
    "plt.title('Loss history')\n",
    "ax = plt.gca()\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(color='gray', linestyle='solid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "LOSS_FIG_PATH = f'{PARAM_PATH}_loss_{model.val_loss_log[-1]:5.2e}.png'\n",
    "plt.savefig(LOSS_FIG_PATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff337cd-3994-4e1f-bca1-bcfad8fa5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_log = [model.val_loss_log,\n",
    " model.val_loss_res_log,\n",
    " model.val_loss_physics_log,\n",
    " model.val_loss_ics_log,\n",
    " model.val_loss_bcs_log,\n",
    " model.val_loss_bnd_physics_log]\n",
    "\n",
    "VAL_LOSS_CSV_PATH = f'{PARAM_PATH}_loss_{model.val_loss_log[-1]:5.2e}_VAL_LOSS.csv'\n",
    "np.savetxt(VAL_LOSS_CSV_PATH, np.stack([np.array(v) for v in val_loss_log]), header='loss res ph ics bcs bcs_ph')\n",
    "\n",
    "train_loss_log = [model.train_loss_log,\n",
    " model.train_loss_res_log,\n",
    " model.train_loss_physics_log,\n",
    " model.train_loss_ics_log,\n",
    " model.train_loss_bcs_log,\n",
    " model.train_loss_bnd_physics_log]\n",
    "\n",
    "TRAIN_LOSS_CSV_PATH = f'{PARAM_PATH}_loss_{model.val_loss_log[-1]:5.2e}_TRAIN_LOSS.csv'\n",
    "np.savetxt(TRAIN_LOSS_CSV_PATH, np.stack([np.array(v) for v in train_loss_log]), header='loss res ph ics bcs bcs_ph')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c83814-b5a1-47a1-ab1a-85e1bb116b81",
   "metadata": {},
   "source": [
    "## Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353cebc2-cefd-437a-b281-6f0fc650857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "str_loss = f'{model.val_loss_log[-1]:5.2e}_FF'\n",
    "str_datetime = datetime.now().strftime(\"%m-%d-%Y-%H%M%S\")\n",
    "PARAM_FILENAME = f'{PARAM_PATH}_loss_{str_loss}_{str_datetime}_FF.pkl'\n",
    "pickle.dump(model.params, open(PARAM_FILENAME, 'wb'))\n",
    "\n",
    "str_loss_best = f'{model.best_model_loss:5.2e}_FF_best'\n",
    "PARAM_FILENAME_BEST = f'{PARAM_PATH}_loss_{str_loss_best}_{str_datetime}_FF.pkl'\n",
    "pickle.dump(model.best_model_params, open(PARAM_FILENAME_BEST, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax (shared)",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
